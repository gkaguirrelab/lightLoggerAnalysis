{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import extract_eye_features\n",
    "import dill\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "# Import the path to Pi_util\n",
    "import sys \n",
    "sys.path.append(\"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility\")\n",
    "import Pi_util\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bfdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a playable video\n",
    "path_to_recording_chunks: str = \"/Volumes/T7 Shield/FLIC_2004_gazeCalibration_tf_session1\"\n",
    "output_dir: str = \"./STORAGE_FOLDER/VIDEO_FOLDER\"\n",
    "Pi_util.generate_playable_videos(path_to_recording_chunks, output_dir, apply_digital_gain=True, fill_missing_frames=True, debayer_images=True, pupil_image_rotation_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fad1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to extract pupil + eyelid features from this video \n",
    "importlib.reload(extract_eye_features)\n",
    "path_to_video: str = \"./FLIC_200X_gazeCalibration_session1/P.avi\"\n",
    "eye_features, perimeter_dict = extract_eye_features.extract_eye_features(path_to_video, \n",
    "                                                                         is_grayscale=True, \n",
    "                                                                         visualize_results=True, \n",
    "                                                                         method='pylids',\n",
    "                                                                         safe_execution=True,\n",
    "                                                                         keypoint_threshold=-1\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72503532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to extract only pupil features from this video \n",
    "importlib.reload(extract_eye_features)\n",
    "path_to_video: str = \"/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/walkIndoor/temporalFrequency/P.avi\"\n",
    "pupil_features, perimeter_dict = extract_eye_features.extract_pupil_features(path_to_video, \n",
    "                                                                             is_grayscale=True, \n",
    "                                                                             visualize_results=True, \n",
    "                                                                             method='pylids',\n",
    "                                                                             safe_execution=True,\n",
    "                                                                             keypoint_threshold=-1,\n",
    "                                                                             visualization_output_filepath=\"/Users/zacharykelly/Desktop/FLIC_2005_walkIndoor_tf_visualizedPupilFeatures.avi\"\n",
    "                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28968936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2001/walkIndoor/temporalFrequency/P_contrast-1x5.avi']\n",
      "Generating: /Users/zacharykelly/Desktop/high_contrast_perimeter_files/FLIC_2001/walkIndoor/temporalFrequency/P_contrast-1x5_perimeter.mat\n",
      "Model weights already exist!\n",
      "Analyzing videos with /Users/zacharykelly/Library/Application Support/pylids/pytorch-pupil-v1/dlc-models-pytorch/iteration-0/santini_eyelid_detectionJul182025-trainset99shuffle1/train/snapshot-best-220.pt\n",
      "Starting to analyze /Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/walkIndoor/temporalFrequency/P.avi\n",
      "Video metadata: \n",
      "  Overall # of frames:    45833\n",
      "  Duration of video [s]:  381.94\n",
      "  fps:                    120.0\n",
      "  resolution:             w=400, h=400\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45833/45833 [17:38<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpmgc0ordh/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5 and /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpmgc0ordh/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "['/var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpmgc0ordh/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5']\n",
      "/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2001/gazeCalibration/temporalFrequency has no contrast videos\n",
      "['/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2003/walkIndoor/temporalFrequency/P_contrast-1x5.avi']\n",
      "Generating: /Users/zacharykelly/Desktop/high_contrast_perimeter_files/FLIC_2003/walkIndoor/temporalFrequency/P_contrast-1x5_perimeter.mat\n",
      "Model weights already exist!\n",
      "Analyzing videos with /Users/zacharykelly/Library/Application Support/pylids/pytorch-pupil-v1/dlc-models-pytorch/iteration-0/santini_eyelid_detectionJul182025-trainset99shuffle1/train/snapshot-best-220.pt\n",
      "Starting to analyze /Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/walkIndoor/temporalFrequency/P.avi\n",
      "Video metadata: \n",
      "  Overall # of frames:    45833\n",
      "  Duration of video [s]:  381.94\n",
      "  fps:                    120.0\n",
      "  resolution:             w=400, h=400\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45833/45833 [17:26<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp2qsu0atv/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5 and /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp2qsu0atv/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "['/var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp2qsu0atv/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5']\n",
      "/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2003/gazeCalibration/temporalFrequency has no contrast videos\n",
      "['/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2004/walkIndoor/temporalFrequency/P_contrast-1x5.avi']\n",
      "Generating: /Users/zacharykelly/Desktop/high_contrast_perimeter_files/FLIC_2004/walkIndoor/temporalFrequency/P_contrast-1x5_perimeter.mat\n",
      "Model weights already exist!\n",
      "Analyzing videos with /Users/zacharykelly/Library/Application Support/pylids/pytorch-pupil-v1/dlc-models-pytorch/iteration-0/santini_eyelid_detectionJul182025-trainset99shuffle1/train/snapshot-best-220.pt\n",
      "Starting to analyze /Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/walkIndoor/temporalFrequency/P.avi\n",
      "Video metadata: \n",
      "  Overall # of frames:    45833\n",
      "  Duration of video [s]:  381.94\n",
      "  fps:                    120.0\n",
      "  resolution:             w=400, h=400\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45833/45833 [17:27<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpfcbd4d3f/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5 and /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpfcbd4d3f/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "['/var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpfcbd4d3f/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5']\n",
      "/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2004/gazeCalibration/temporalFrequency has no contrast videos\n",
      "['/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/walkIndoor/temporalFrequency/P_contrast-1x5.avi']\n",
      "Generating: /Users/zacharykelly/Desktop/high_contrast_perimeter_files/FLIC_2005/walkIndoor/temporalFrequency/P_contrast-1x5_perimeter.mat\n",
      "Model weights already exist!\n",
      "Analyzing videos with /Users/zacharykelly/Library/Application Support/pylids/pytorch-pupil-v1/dlc-models-pytorch/iteration-0/santini_eyelid_detectionJul182025-trainset99shuffle1/train/snapshot-best-220.pt\n",
      "Starting to analyze /Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/walkIndoor/temporalFrequency/P.avi\n",
      "Video metadata: \n",
      "  Overall # of frames:    45833\n",
      "  Duration of video [s]:  381.94\n",
      "  fps:                    120.0\n",
      "  resolution:             w=400, h=400\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45833/45833 [17:29<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpr80danxj/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5 and /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpr80danxj/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "['/var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmpr80danxj/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5']\n",
      "/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/gazeCalibration/temporalFrequency has no contrast videos\n",
      "['/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2002/walkIndoor/temporalFrequency/P_contrast-1x5.avi']\n",
      "Generating: /Users/zacharykelly/Desktop/high_contrast_perimeter_files/FLIC_2002/walkIndoor/temporalFrequency/P_contrast-1x5_perimeter.mat\n",
      "Model weights already exist!\n",
      "Analyzing videos with /Users/zacharykelly/Library/Application Support/pylids/pytorch-pupil-v1/dlc-models-pytorch/iteration-0/santini_eyelid_detectionJul182025-trainset99shuffle1/train/snapshot-best-220.pt\n",
      "Starting to analyze /Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2005/walkIndoor/temporalFrequency/P.avi\n",
      "Video metadata: \n",
      "  Overall # of frames:    45833\n",
      "  Duration of video [s]:  381.94\n",
      "  fps:                    120.0\n",
      "  resolution:             w=400, h=400\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45833/45833 [18:13<00:00, 41.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp0i703qrl/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5 and /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp0i703qrl/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "['/var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp0i703qrl/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5']\n",
      "/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2002/gazeCalibration/temporalFrequency has no contrast videos\n",
      "/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2006/walkIndoor/temporalFrequency has no contrast videos\n",
      "/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2006/gazeCalibration/temporalFrequency has no contrast videos\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the external SSD that contains the videos \n",
    "SSD_path: str = \"/Volumes/T7 Shield/scriptedIndoorOutdoorVideos\"\n",
    "output_path: str = \"/Users/zacharykelly/Desktop/high_contrast_perimeter_files\"\n",
    "\n",
    "# Iterate over the subjects that we have \n",
    "for subject_id in os.listdir(SSD_path):\n",
    "    # Skip hidden files \n",
    "    if(subject_id.startswith(\".\")):\n",
    "        continue \n",
    "    \n",
    "    # Otherwise, construct the path to the subjecty \n",
    "    subject_path: str = os.path.join(SSD_path, subject_id)\n",
    "\n",
    "    # Iterate over the activites of the subject \n",
    "    for activitiy in os.listdir(subject_path):\n",
    "        # Skip hidden files \n",
    "        if(activitiy.startswith(\".\")):\n",
    "            continue \n",
    "        \n",
    "        # If the activity is not gazecal or walkindoor just skip \n",
    "        if(not (\"gaze\" in activitiy or \"walkIndoor\" in activitiy)):\n",
    "            continue \n",
    "\n",
    "        # Construct the path to the activity \n",
    "        activitiy_path: str = os.path.join(subject_path, activitiy)\n",
    "\n",
    "        # Iterate over the modes at this activity \n",
    "        for mode in os.listdir(activitiy_path):\n",
    "            # Skip hidden files \n",
    "            if(mode.startswith(\".\")):\n",
    "                continue \n",
    "            \n",
    "            # Skip spatial resolution \n",
    "            if(\"spatial\" in mode):\n",
    "                continue \n",
    "            \n",
    "            # construct the path to the mode directory \n",
    "            mode_path: str = os.path.join(activitiy_path, mode)\n",
    "\n",
    "            # Find the P contrast videos for this mode \n",
    "            P_contrast_videos: list[str] = [ os.path.join(mode_path, file) for file in os.listdir(mode_path)\n",
    "                                             if \"P\" in file and \"contrast\" in file\n",
    "                                             and not file.startswith(\".\")\n",
    "                                           ]\n",
    "            \n",
    "            # If no contrast, just skip with a message \n",
    "            if(len(P_contrast_videos) == 0):\n",
    "                print(f\"{mode_path} has no contrast videos\")\n",
    "                continue \n",
    "\n",
    "            # Otherwise, we are going to generate the perimeter file for this \n",
    "            print(P_contrast_videos)\n",
    "            for contrast_video_path in P_contrast_videos:\n",
    "                # Find the filename of this file \n",
    "                filename: str = os.path.splitext(os.path.basename(contrast_video_path))[0]\n",
    "\n",
    "                # Construct the path to the visualization output \n",
    "                perimeter_file_output_path: str = os.path.join(output_path, subject_id, activitiy, mode, f\"{filename}_perimeter.mat\")\n",
    "                visualization_output_filepath: str = os.path.join(output_path, subject_id, activitiy, mode, f\"{filename}_visualizedPupilFeatures.avi\")\n",
    "                os.makedirs(visualization_output_filepath, exist_ok=True)\n",
    "\n",
    "                print(f\"Generating: {perimeter_file_output_path}\")\n",
    "\n",
    "                # Generate the perimeter file \n",
    "                pupil_features, perimeter_dict = extract_eye_features.extract_pupil_features(path_to_video, \n",
    "                                                                                             is_grayscale=True, \n",
    "                                                                                             visualize_results=True, \n",
    "                                                                                             method='pylids',\n",
    "                                                                                             safe_execution=True,\n",
    "                                                                                             keypoint_threshold=-1,\n",
    "                                                                                             visualization_output_filepath=visualization_output_filepath\n",
    "                                                                                            )\n",
    "        \n",
    "                # Output the perimeter file as a .mat\n",
    "                scipy.io.savemat(perimeter_file_output_path, {\"perimeter\": perimeter_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da289ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to extract only eyelid features from this video \n",
    "eyelid_features: list[dict] = extract_eye_features.extract_pupil_features(path_to_video, \n",
    "                                                                          is_grayscale=True, \n",
    "                                                                          visualize_results=True, \n",
    "                                                                          method='pylids',\n",
    "                                                                          safe_execution=True,\n",
    "                                                                          keypoint_threshold=-1\n",
    "                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"/Users/zacharykelly/Desktop/FLIC_2005_walkIndoor_tf_perimeter.mat\", {\"perimeter\": perimeter_dict})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
