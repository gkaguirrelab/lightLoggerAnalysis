{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49c2727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc8...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries \n",
    "import extract_eye_features\n",
    "import dill\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "# Import the path to Pi_util\n",
    "import sys \n",
    "sys.path.append(\"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility\")\n",
    "import Pi_util\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "479bfdcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/T7 Shield/FLIC_2004_gazeCalibration_tf_session1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m path_to_recording_chunks: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Volumes/T7 Shield/FLIC_2004_gazeCalibration_tf_session1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m output_dir: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./STORAGE_FOLDER/VIDEO_FOLDER\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mPi_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_playable_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_recording_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_digital_gain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_missing_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebayer_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpupil_image_rotation_correction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility/Pi_util.py:617\u001b[0m, in \u001b[0;36mgenerate_playable_videos\u001b[0;34m(recording_path, output_dir, apply_digital_gain, fill_missing_frames, draw_pupil_ROI, debayer_images, pupil_image_rotation_correction, encryption_password, time_ranges, chunk_ranges, contains_agc_metadata)\u001b[0m\n\u001b[1;32m    607\u001b[0m         parameter_dict[sensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([ \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m range_tuple])\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# First, we must note we have to be smart about how we do this. Recordings \u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# could go on for an infinite number of hours, meaning that we cannot naively \u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# read in all of the chunks then construct this video due to memory constraints. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# Retrieve each of the sensor's files grouped together, exclude the MS \u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# since it will not be turned into a video \u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m sensors_chunks_paths: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_sensors_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m sensors_chunks_paths\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# Find the number of chunks by finding the maximum number of readings from each of the sensors \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility/Pi_util.py:716\u001b[0m, in \u001b[0;36mgroup_sensors_files\u001b[0;34m(recording_path)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroup_sensor_files\u001b[39m(sensor_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ ( os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(recording_path, file), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(recording_path, file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) ) ) \n\u001b[1;32m    712\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m natsorted(os\u001b[38;5;241m.\u001b[39mlistdir(recording_path)) \n\u001b[1;32m    713\u001b[0m                \u001b[38;5;28;01mif\u001b[39;00m sensor_name \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file\n\u001b[1;32m    714\u001b[0m            ]\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {sensor[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper(): group_sensor_files(sensor) \u001b[38;5;66;03m# n chunks = [ (metadata_path, frame_buffer_path), ...  ]\u001b[39;00m\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sensor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworld\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpupil\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m        }\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility/Pi_util.py:716\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroup_sensor_files\u001b[39m(sensor_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ ( os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(recording_path, file), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(recording_path, file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) ) ) \n\u001b[1;32m    712\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m natsorted(os\u001b[38;5;241m.\u001b[39mlistdir(recording_path)) \n\u001b[1;32m    713\u001b[0m                \u001b[38;5;28;01mif\u001b[39;00m sensor_name \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file\n\u001b[1;32m    714\u001b[0m            ]\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {sensor[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper(): \u001b[43mgroup_sensor_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# n chunks = [ (metadata_path, frame_buffer_path), ...  ]\u001b[39;00m\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sensor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworld\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpupil\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m        }\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility/Pi_util.py:712\u001b[0m, in \u001b[0;36mgroup_sensors_files.<locals>.group_sensor_files\u001b[0;34m(sensor_name)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroup_sensor_files\u001b[39m(sensor_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ ( os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(recording_path, file), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(recording_path, file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) ) ) \n\u001b[0;32m--> 712\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m natsorted(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_path\u001b[49m\u001b[43m)\u001b[49m) \n\u001b[1;32m    713\u001b[0m                \u001b[38;5;28;01mif\u001b[39;00m sensor_name \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file\n\u001b[1;32m    714\u001b[0m            ]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/T7 Shield/FLIC_2004_gazeCalibration_tf_session1'"
     ]
    }
   ],
   "source": [
    "# Generate a playable video\n",
    "path_to_recording_chunks: str = \"/Volumes/T7 Shield/FLIC_2004_gazeCalibration_tf_session1\"\n",
    "output_dir: str = \"./STORAGE_FOLDER/VIDEO_FOLDER\"\n",
    "Pi_util.generate_playable_videos(path_to_recording_chunks, output_dir, apply_digital_gain=True, fill_missing_frames=True, debayer_images=True, pupil_image_rotation_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47fad1b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_eye_features() got an unexpected keyword argument 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(extract_eye_features)\n\u001b[1;32m      3\u001b[0m path_to_video: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./FLIC_200X_gazeCalibration_session1/P.avi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m eye_features, perimeter_dict \u001b[38;5;241m=\u001b[39m \u001b[43mextract_eye_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_eye_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mis_grayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mvisualize_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpylids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43msafe_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mkeypoint_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: extract_eye_features() got an unexpected keyword argument 'method'"
     ]
    }
   ],
   "source": [
    "# Attempt to extract pupil + eyelid features from this video \n",
    "importlib.reload(extract_eye_features)\n",
    "path_to_video: str = \"./FLIC_200X_gazeCalibration_session1/P.avi\"\n",
    "eye_features, perimeter_dict = extract_eye_features.extract_eye_features(path_to_video, \n",
    "                                                                         is_grayscale=True, \n",
    "                                                                         visualize_results=True, \n",
    "                                                                         method='pylids',\n",
    "                                                                         safe_execution=True,\n",
    "                                                                         keypoint_threshold=-1\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72503532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights already exist!\n",
      "Analyzing videos with /Users/zacharykelly/Library/Application Support/pylids/pytorch-pupil-v1/dlc-models-pytorch/iteration-0/santini_eyelid_detectionJul182025-trainset99shuffle1/train/snapshot-best-220.pt\n",
      "Starting to analyze /Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2001/walkIndoor/temporalFrequency/P.avi\n",
      "Video metadata: \n",
      "  Overall # of frames:    64212\n",
      "  Duration of video [s]:  535.10\n",
      "  fps:                    120.0\n",
      "  resolution:             w=400, h=400\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64212/64212 [24:29<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp5i56kdgf/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5 and /var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp5i56kdgf/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "['/var/folders/g_/1p95771n5l1f_f8gbbftkjy80000gn/T/tmp5i56kdgf/PDLC_Resnet50_santini_eyelid_detectionJul182025shuffle1_snapshot_220.h5']\n"
     ]
    }
   ],
   "source": [
    "# Attempt to extract only pupil features from this video \n",
    "importlib.reload(extract_eye_features)\n",
    "path_to_video: str = \"/Volumes/T7 Shield/scriptedIndoorOutdoorVideos/FLIC_2002/walkIndoor/temporalFrequency/P.avi\"\n",
    "pupil_features, perimeter_dict = extract_eye_features.extract_pupil_features(path_to_video, \n",
    "                                                                             is_grayscale=True, \n",
    "                                                                             visualize_results=True, \n",
    "                                                                             method='pylids',\n",
    "                                                                             safe_execution=True,\n",
    "                                                                             keypoint_threshold=-1,\n",
    "                                                                             visualization_output_filepath=\"/Users/zacharykelly/Desktop/FLIC_2002_walkIndoor_tf_visualizedPupilFeatures.avi\"\n",
    "                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da289ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to extract only eyelid features from this video \n",
    "eyelid_features: list[dict] = extract_eye_features.extract_pupil_features(path_to_video, \n",
    "                                                                          is_grayscale=True, \n",
    "                                                                          visualize_results=True, \n",
    "                                                                          method='pylids',\n",
    "                                                                          safe_execution=True,\n",
    "                                                                          keypoint_threshold=-1\n",
    "                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b0c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"/Users/zacharykelly/Desktop/FLIC_2001_walkIndoor_tf_perimeter.mat\", {\"perimeter\": perimeter_dict})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
