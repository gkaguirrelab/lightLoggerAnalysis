{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0214210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc8...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import extract_gaze_stimulus\n",
    "import sys \n",
    "sys.path.append(\"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility\")\n",
    "import Pi_util\n",
    "import importlib\n",
    "import scipy.io \n",
    "from scipy.signal import find_peaks\n",
    "import matlab.engine\n",
    "import tqdm \n",
    "import warnings\n",
    "import virtual_foveation\n",
    "import hdf5storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a playable video\n",
    "path_to_recording_chunks: str = \"/Volumes/T7 Shield/sam_gazecal_106\"\n",
    "output_dir: str = \"./\"\n",
    "Pi_util.generate_playable_videos(path_to_recording_chunks, output_dir, apply_digital_gain=True, fill_missing_frames=True, debayer_images=True, pupil_image_rotation_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d049727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the frames of the recording \n",
    "world_frames: np.ndarray = Pi_util.destruct_video(\"./sam_gazecal_106/W.avi\", is_grayscale=True)\n",
    "print(world_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate an array of transformed frames \n",
    "transformed_world_frames: np.ndarray = np.zeros_like(world_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4df5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the pupil gaze angles \n",
    "gaze_angles: np.ndarray = np.nan_to_num(scipy.io.loadmat(\"./gaze_angles\")[\"gaze_angles\"], 0)\n",
    "print(gaze_angles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27097863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the first chunk of both cameras. This will tell us if one or the other started first \n",
    "world_start_chunk_metadata: np.array = np.load(\"/Volumes/T7 Shield/sam_gazecal_106/world_time_2025DASH10DASH06_09COLON26COLON14DOT693525_chunk_0_metadata.npy\")\n",
    "pupil_start_chunk_metadata: np.array = np.load(\"/Volumes/T7 Shield/sam_gazecal_106/pupil_time_2025DASH10DASH06_09COLON26COLON15DOT252214_chunk_0_metadata.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the missing number of frames between the two measurements in time \n",
    "FPS: float = 120\n",
    "missing_frames: int = (abs(len(world_frames) - len(gaze_angles)))\n",
    "missing_time: float = missing_frames / FPS \n",
    "print(missing_frames)\n",
    "print(missing_time)\n",
    "\n",
    "# Print the start time of both cameras so we can see whcih is first \n",
    "print(world_start_chunk_metadata[0, 0] / (10 ** 9))\n",
    "print(pupil_start_chunk_metadata[0, 0])\n",
    "\n",
    "# Find the difference explained by this \n",
    "start_time_delay_time: float = abs(pupil_start_chunk_metadata[0, 0] - world_start_chunk_metadata[0, 0] / (10 ** 9))\n",
    "start_time_delay_frames: int = int(np.ceil(start_time_delay_time * FPS))\n",
    "print(start_time_delay_time)\n",
    "print(start_time_delay_frames)\n",
    "\n",
    "# Account for the fact that we measured the pupil camera time wise is 0.005 phase advanced \n",
    "pupil_phase_offset_seconds: float = 0.005\n",
    "start_time_delay_time -= pupil_phase_offset_seconds\n",
    "start_time_delay_frames -= int(np.ceil(pupil_phase_offset_seconds * FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new MATLAB session\n",
    "eng: object = matlab.engine.start_matlab()\n",
    "eng.tbUseProject(\"lightLoggerAnalysis\", nargout=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the objects we will use \n",
    "intrinsics_path: str = \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis/code/virtual_foveation_wip/intrinsics_calibration.mat\"\n",
    "transformation_path: str = \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis/code/virtual_foveation_wip/perspective_transform\"\n",
    "\n",
    "intrinsics: dict = scipy.io.loadmat(intrinsics_path)[\"camera_intrinsics_calibration\"]\n",
    "transformation: dict = scipy.io.loadmat(transformation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5365eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformation[\"perspective_transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c87d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the world frames \n",
    "frames_for_video: int = len(world_frames) #(start_time_delay_frames) + (120 * 5) # len(world_frames)\n",
    "for world_frame_num in tqdm.trange(start_time_delay_frames, frames_for_video):    \n",
    "    print(f\"Processing frame: {world_frame_num+1}/{frames_for_video}\", flush=True)\n",
    "\n",
    "    # Retrieve the pupil frame that corresponds to this world camera frame \n",
    "    pupil_frame_num: int = world_frame_num - start_time_delay_frames\n",
    "\n",
    "    # If we have gone out of bounds for pupil, simply quit \n",
    "    if(pupil_frame_num >= len(gaze_angles)):\n",
    "        warnings.warn(f\"{pupil_frame_num} Out of bounds for pupil frame, breaking\")\n",
    "        break \n",
    "\n",
    "    # Otherwise, retrieve the gaze angles for this pupil frame \n",
    "    # and world frame \n",
    "    world_frame: np.ndarray = world_frames[world_frame_num]\n",
    "    pupil_gaze_angles: np.ndarray = gaze_angles[pupil_frame_num, :2]\n",
    "    \n",
    "    # If there is nan gaze angles, just skip this frame \n",
    "    # and leave it all 0s\n",
    "    if(np.any(np.isnan(pupil_gaze_angles))):\n",
    "        continue\n",
    "\n",
    "    # Then feed this as input into MATLAB to generate the correced frame \n",
    "    transformed_world_frame: np.ndarray = np.array(eng.coordinateTransformFinal(matlab.double(np.ascontiguousarray(world_frame).astype(np.float64)),\n",
    "                                                                                intrinsics_path, \n",
    "                                                                                transformation_path,\n",
    "                                                                                matlab.double(np.ascontiguousarray(pupil_gaze_angles[::-1].astype(np.float64))),\n",
    "                                                                                nargout=1\n",
    "                                                                               ))\n",
    "    transformed_world_frame = np.clip(transformed_world_frame * 255, 0, 255).astype(np.uint8)    \n",
    "    transformed_world_frame = np.flipud(transformed_world_frame)\n",
    "\n",
    "    transformed_world_frames[world_frame_num] = transformed_world_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2436c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the MATLAB engine \n",
    "eng.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ed106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Pi_util.frames_to_video(transformed_world_frames, output_path=\"virtually_foveated_video.avi\", fps=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
