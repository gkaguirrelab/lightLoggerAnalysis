{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0214210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc8...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import extract_gaze_stimulus\n",
    "import sys \n",
    "sys.path.append(\"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger/raspberry_pi_firmware/utility\")\n",
    "import Pi_util\n",
    "import importlib\n",
    "import scipy.io \n",
    "from scipy.signal import find_peaks\n",
    "import matlab.engine\n",
    "import tqdm \n",
    "import warnings\n",
    "import virtual_foveation\n",
    "import hdf5storage\n",
    "import dill \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a playable video\n",
    "path_to_recording_chunks: str = \"/Volumes/T7 Shield/sam_gazecal_106\"\n",
    "output_dir: str = \"./\"\n",
    "Pi_util.generate_playable_videos(path_to_recording_chunks, output_dir, apply_digital_gain=True, fill_missing_frames=True, debayer_images=True, pupil_image_rotation_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d049727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25792, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Load in the frames of the recording \n",
    "world_frames: np.ndarray = Pi_util.destruct_video(\"./sam_gazecal_106/W.avi\", is_grayscale=True)\n",
    "print(world_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(world_frames[21000], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a88234",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx: np.ndarray = np.array([i for i in range(15000, 16000, 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in world_frames[frame_idx]:\n",
    "    plt.imshow(frame, cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17529076",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"sam106GazeCal_testframes.mat\", {\"frames\": world_frames[frame_idx]}) # 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate an array of transformed frames \n",
    "transformed_world_frames: np.ndarray = np.zeros_like(world_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4df5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25717, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load in the pupil gaze angles \n",
    "gaze_angles: np.ndarray = np.nan_to_num(scipy.io.loadmat(\"./gaze_angles\")[\"gaze_angles\"], 0)\n",
    "print(gaze_angles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"sam106GazeCal_gaze_angles.mat\", {\"gaze_angles\": gaze_angles[frame_idx - 65]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27097863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the first chunk of both cameras. This will tell us if one or the other started first \n",
    "world_start_chunk_metadata: np.array = np.load(\"/Volumes/T7 Shield/sam_gazecal_106/world_time_2025DASH10DASH06_09COLON26COLON14DOT693525_chunk_0_metadata.npy\")\n",
    "pupil_start_chunk_metadata: np.array = np.load(\"/Volumes/T7 Shield/sam_gazecal_106/pupil_time_2025DASH10DASH06_09COLON26COLON15DOT252214_chunk_0_metadata.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8f2d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "0.625\n",
      "3639.024468\n",
      "3639.559819\n",
      "0.5353509999999915\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# Find the missing number of frames between the two measurements in time \n",
    "FPS: float = 120\n",
    "missing_frames: int = (abs(len(world_frames) - len(gaze_angles)))\n",
    "missing_time: float = missing_frames / FPS \n",
    "print(missing_frames)\n",
    "print(missing_time)\n",
    "\n",
    "# Print the start time of both cameras so we can see whcih is first \n",
    "print(world_start_chunk_metadata[0, 0] / (10 ** 9))\n",
    "print(pupil_start_chunk_metadata[0, 0])\n",
    "\n",
    "# Find the difference explained by this \n",
    "start_time_delay_time: float = abs(pupil_start_chunk_metadata[0, 0] - world_start_chunk_metadata[0, 0] / (10 ** 9))\n",
    "start_time_delay_frames: int = int(np.ceil(start_time_delay_time * FPS))\n",
    "print(start_time_delay_time)\n",
    "print(start_time_delay_frames)\n",
    "\n",
    "# Account for the fact that we measured the pupil camera time wise is 0.005 phase advanced \n",
    "pupil_phase_offset_seconds: float = 0.005\n",
    "start_time_delay_time -= pupil_phase_offset_seconds\n",
    "start_time_delay_frames -= int(np.ceil(pupil_phase_offset_seconds * FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0c688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locating project \"lightLoggerAnalysis\" within \"/Users/zacharykelly/Documents/MATLAB/projects\".\n",
      "  Found at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis\".\n",
      "Local copy of ToolboxToolbox is up to date.\n",
      "Updating \"ToolboxRegistry\".\n",
      "Already up to date.\n",
      "Updating \"lightLoggerAnalysis\".\n",
      "Already up to date.\n",
      "Locating project \"lightLogger\" within \"/Users/zacharykelly/Documents/MATLAB/projects\".\n",
      "  Found at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger\".\n",
      "Updating \"lightLogger\".\n",
      "Already up to date.\n",
      "Updating \"combiLEDToolbox\".\n",
      "Already up to date.\n",
      "Updating \"BrainardLabToolbox\".\n",
      "Already up to date.\n",
      "Updating \"WatsonYellott2012_PupilSize\".\n",
      "Already up to date.\n",
      "Updating \"bads\".\n",
      "Already up to date.\n",
      "Updating \"export_fig\".\n",
      "Already up to date.\n",
      "Updating \"Psychtoolbox-3\".\n",
      "Already up to date.\n",
      "Updating \"SilentSubstitutionToolbox\".\n",
      "Already up to date.\n",
      "Updating \"ExampleTestToolbox\".\n",
      "Already up to date.\n",
      "Resetting path to factory state.\n",
      "Adding \"ToolboxToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/ToolboxToolbox\".\n",
      "Adding \"lightLoggerAnalysis\" to path at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis\".\n",
      "Locating project \"lightLogger\" within \"/Users/zacharykelly/Documents/MATLAB/projects\".\n",
      "  Found at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger\".\n",
      "Adding \"lightLogger\" to path at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger\".\n",
      "Adding \"combiLEDToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/combiLEDToolbox/code\".\n",
      "Adding \"BrainardLabToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/BrainardLabToolbox/LabJackToolbox\".\n",
      "Adding \"BrainardLabToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/BrainardLabToolbox/Plotting\".\n",
      "Adding \"BrainardLabToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/BrainardLabToolbox/OneLiners\".\n",
      "Adding \"BrainardLabToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/BrainardLabToolbox/Overrides\".\n",
      "Adding \"BrainardLabToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/BrainardLabToolbox/OOCalibrationToolbox\".\n",
      "Adding \"WatsonYellott2012_PupilSize\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/WatsonYellott2012_PupilSize\".\n",
      "Adding \"bads\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/bads\".\n",
      "Adding \"export_fig\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/export_fig\".\n",
      "Adding \"Psychtoolbox-3\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/Psychtoolbox-3/Psychtoolbox\".\n",
      "Adding \"SilentSubstitutionToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/SilentSubstitutionToolbox\".\n",
      "Adding \"ExampleTestToolbox\" to path at \"/Users/zacharykelly/Documents/MATLAB/toolboxes/ExampleTestToolbox\".\n",
      "Checking for \"lightLoggerAnalysis\" local hook.\n",
      "  Running local hook \"/Users/zacharykelly/Documents/MATLAB/localHookFolder/lightLoggerAnalysisLocalHook.m\".\n",
      "Locating project \"lightLoggerAnalysis\" within \"/Users/zacharykelly/Documents/MATLAB/projects\".\n",
      "  Found at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis\".\n",
      "Locating project \"lightLogger\" within \"/Users/zacharykelly/Documents/MATLAB/projects\".\n",
      "  Found at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLogger\".\n",
      "Locating project \"combiExperiments\" within \"/Users/zacharykelly/Documents/MATLAB/projects\".\n",
      "  Found at \"/Users/zacharykelly/Documents/MATLAB/projects/combiExperiments\".\n",
      "Locating project \"lightLoggerAnalysis\" within \"/Users/zacharykelly/Documents/MATLAB/projects\".\n",
      "  Found at \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis\".\n",
      "  Hook success with status 0.\n",
      "Checking for \"lightLogger\" local hook.\n",
      "  Running local hook \"/Users/zacharykelly/Documents/MATLAB/localHookFolder/lightLoggerLocalHook.m\".\n",
      "  Hook success with status 0.\n",
      "Checking for \"combiLEDToolbox\" local hook.\n",
      "  Running local hook \"/Users/zacharykelly/Documents/MATLAB/localHookFolder/combiLEDToolboxLocalHook.m\".\n",
      "Warning: The Matlab Optimization Toolbox is missing. combiLEDToolbox may not function properly.\n",
      "  Hook success with status 0.\n",
      "Checking for \"BrainardLabToolbox\" local hook.\n",
      "Checking for \"WatsonYellott2012_PupilSize\" local hook.\n",
      "Checking for \"bads\" local hook.\n",
      "Checking for \"export_fig\" local hook.\n",
      "Checking for \"Psychtoolbox-3\" local hook.\n",
      "Checking for \"SilentSubstitutionToolbox\" local hook.\n",
      "Checking for \"ExampleTestToolbox\" local hook.\n",
      "Looks good: 10 resolved toolboxes deployed OK.\n"
     ]
    }
   ],
   "source": [
    "# Start a new MATLAB session\n",
    "eng: object = matlab.engine.start_matlab()\n",
    "eng.tbUseProject(\"lightLoggerAnalysis\", nargout=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6da3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the objects we will use \n",
    "intrinsics_path: str = \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis/code/virtual_foveation_wip/intrinsics_calibration.mat\"\n",
    "transformation_path: str = \"/Users/zacharykelly/Documents/MATLAB/projects/lightLoggerAnalysis/code/virtual_foveation_wip/perspective_transform\"\n",
    "\n",
    "intrinsics: dict = scipy.io.loadmat(intrinsics_path)[\"camera_intrinsics_calibration\"]\n",
    "transformation: dict = scipy.io.loadmat(transformation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5365eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformation[\"perspective_transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c87d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the world frames \n",
    "frames_for_video: int = len(world_frames) #(start_time_delay_frames) + (120 * 5) # len(world_frames)\n",
    "frames_transformed = []\n",
    "for world_frame_num in tqdm.trange(start_time_delay_frames+15000, start_time_delay_frames+16000):    \n",
    "    print(f\"Processing frame: {world_frame_num+1}/{frames_for_video}\", flush=True)\n",
    "\n",
    "    # Retrieve the pupil frame that corresponds to this world camera frame \n",
    "    pupil_frame_num: int = world_frame_num - start_time_delay_frames\n",
    "\n",
    "    # If we have gone out of bounds for pupil, simply quit \n",
    "    if(pupil_frame_num >= len(gaze_angles)):\n",
    "        warnings.warn(f\"{pupil_frame_num} Out of bounds for pupil frame, breaking\")\n",
    "        break \n",
    "\n",
    "    # Otherwise, retrieve the gaze angles for this pupil frame \n",
    "    # and world frame \n",
    "    world_frame: np.ndarray = world_frames[world_frame_num]\n",
    "    pupil_gaze_angles: np.ndarray = gaze_angles[pupil_frame_num, :2]\n",
    "    pupil_gaze_angles[0] = -pupil_gaze_angles[0]\n",
    "    pupil_gaze_angles[1] -= 5.4\n",
    "\n",
    "    # If there is nan gaze angles, just skip this frame \n",
    "    # and leave it all 0s\n",
    "    if(np.any(np.isnan(pupil_gaze_angles))):\n",
    "        continue\n",
    "\n",
    "    # Then feed this as input into MATLAB to generate the correced frame \n",
    "    transformed_world_frame: np.ndarray = np.array(eng.coordinateTransformFinal(matlab.double(np.ascontiguousarray(world_frame).astype(np.float64)),\n",
    "                                                                                matlab.double(np.ascontiguousarray(pupil_gaze_angles.astype(np.float64))),\n",
    "                                                                                intrinsics_path, \n",
    "                                                                                transformation_path,\n",
    "                                                                                nargout=1\n",
    "                                                                               ))\n",
    "    \n",
    "    frames_transformed.append(transformed_world_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2436c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the MATLAB engine \n",
    "eng.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ed106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Pi_util.frames_to_video(padded_frames, output_path=\"virtually_foveated_video.avi\", fps=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inhomogenous_frames.pkl\", \"wb\") as f:\n",
    "    dill.dump(frames_transformed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffa11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_test = None \n",
    "with open(\"inhomogenous_frames.pkl\", \"rb\") as f:\n",
    "    frames_test = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87682920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "\n",
    "frame_size_frequency_counter: collections.Counter = collections.Counter([frame.shape for frame in frames_transformed])\n",
    "max_size, count = frame_size_frequency_counter.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51490f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will iterate through the frames and pad the ones that are not max size \n",
    "padded_frames: np.ndarray = np.zeros((len(frames_transformed), *max_size[:2]), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_frame(frame, target_shape, constant_value=0):\n",
    "    \"\"\"\n",
    "    Pad a frame (H×W×C) to target_shape=(target_H, target_W[, C])\n",
    "    using constant padding (default black).\n",
    "    \"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    target_h, target_w = target_shape[:2]\n",
    "\n",
    "    # Compute padding for each side\n",
    "    pad_top = (target_h - h) // 2\n",
    "    pad_bottom = target_h - h - pad_top\n",
    "    pad_left = (target_w - w) // 2\n",
    "    pad_right = target_w - w - pad_left\n",
    "\n",
    "    # Apply padding\n",
    "    if frame.ndim == 3:\n",
    "        padded = np.pad(frame,\n",
    "                        ((pad_top, pad_bottom),\n",
    "                         (pad_left, pad_right),\n",
    "                         (0, 0)),\n",
    "                        mode='constant',\n",
    "                        constant_values=constant_value)\n",
    "    else:\n",
    "        padded = np.pad(frame,\n",
    "                        ((pad_top, pad_bottom),\n",
    "                         (pad_left, pad_right)),\n",
    "                        mode='constant',\n",
    "                        constant_values=constant_value)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fa458",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx in tqdm.tqdm(range(len(frames_transformed))):\n",
    "    try:\n",
    "        padded_frames[frame_idx] = cv2.cvtColor( frames_transformed[frame_idx], cv2.COLOR_RGB2GRAY )\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085af662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find solely the inhomogenously sized frames \n",
    "inhomogenous_frames: list = [frame for frame in frames_test if frame.shape != max_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a673dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inhomogenous_frames)/len(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in inhomogenous_frames:\n",
    "    plt.imshow(frame, cmap='gray')\n",
    "    plt.title(f\"Size: {frame.shape}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
